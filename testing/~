import os
import sys
import time
import glob
import numpy as np
import torch
import utils
import logging
import argparse
import torch.nn as nn
import torch.utils
import torch.nn.functional as F
import torchvision.datasets as dset
import torch.backends.cudnn as cudnn
import genotypes
import pdb
import torch
from sklearn import metrics
#torch.multiprocessing.set_start_method("spawn")
from functions import seq2num,element,combination,hilbert_curve,plot_hb_dna,read_file,plot_row1,snake_curve
from torch.autograd import Variable
#from model_search import Network
from model import NetworkCIFAR as Network
from architect import Architect
import torch.utils.data as data_utils
from torch.utils.data.sampler import SubsetRandomSampler
use_plot = True
use_save = True
if use_save:
    import pickle
    from datetime import datetime
parser = argparse.ArgumentParser("TEST SPLICE SITE CLASSIFICATION")
#parser.add_argument('--data', type=str, default='/gpfs/projects/apptest/project/darts/shab_test/testsplice', help='location of the data corpus')
parser.add_argument('--batch_size', type=int, default=100, help='batch size')
parser.add_argument('--data', type=str, help='data_species')
parser.add_argument('--type', type=str, help='typ')
parser.add_argument('--test_file', type=str, help='testfile')
#parser.add_argument('--model', type=str, help='model_species')
parser.add_argument('--val_size', type=int, default=500, help='validation batch size')
#parser.add_argument('--learning_rate', type=float, default=0.0025, help='init learning rate')
#parser.add_argument('--learning_rate_min', type=float, default=0.0001, help='min learning rate')
#parser.add_argument('--momentum', type=float, default=0.9, help='momentum')
#parser.add_argument('--weight_decay', type=float, default=3e-4, help='weight decay')
parser.add_argument('--report_freq', type=float, default=500, help='report frequency')
#parser.add_argument('--gpu', type=int, default=1, help='gpu device id')
#parser.add_argument('--epochs', type=int, default=50, help='num of training epochs')
#parser.add_argument('--init_channels', type=int, default=16, help='num of init channels')
#parser.add_argument('--layers', type=int, default=3, help='total number of layers')
#parser.add_argument('--auxiliary', action='store_true', default=False, help='use auxiliary tower')
#parser.add_argument('--auxiliary_weight', type=float, default=0.4, help='weight for auxiliary loss')
#parser.add_argument('--model_path', type=str, default='saved_models', help='path to save the model')
#parser.add_argument('--cutout', action='store_true', default=False, help='use cutout')
#parser.add_argument('--cutout_length', type=int, default=16, help='cutout length')
#parser.add_argument('--drop_path_prob', type=float, default=0.2, help='drop path probability')
#parser.add_argument('--save', type=str, default='CELEGANS_ACC', help='experiment name')
parser.add_argument('--seed', type=int, default=2, help='random seed')
#parser.add_argument('--grad_clip', type=float, default=5, help='gradient clipping')
#parser.add_argument('--train_portion', type=float, default=0.8, help='portion of training data')
#parser.add_argument('--valid_portion', type=float, default=0.9, help='portion of validation data')
#parser.add_argument('--arch', type=str, default='celegans_acc', help='which architecture to use')
#parser.add_argument('--unrolled', action='store_true', default=True, help='use one-step unrolled validation loss')
#parser.add_argument('--arch_learning_rate', type=float, default=3e-4, help='learning rate for arch encoding')
#parser.add_argument('--arch_weight_decay', type=float, default=1e-3, help='weight decay for arch encoding')
args = parser.parse_args()

#args.save = 'eval-CELEGANS_ACC-{}-{}'.format(args.save, time.strftime("%Y%m%d-%H%M%S"))
#utils.create_exp_dir(args.save, scripts_to_save=glob.glob('*.py'))

log_format = '%(asctime)s %(message)s'
logging.basicConfig(stream=sys.stdout, level=logging.INFO,
    format=log_format, datefmt='%m/%d %I:%M:%S %p')
#fh = logging.FileHandler(os.path.join(args.save, 'log.txt'))
#fh.setFormatter(logging.Formatter(log_format))
#logging.getLogger().addHandler(fh)


CIFAR_CLASSES = 2


# def main():
#     if not torch.cuda.is_available():
#         logging.info('no gpu device available')
#   sys.exit(1)

#np.random.seed(args.seed)
#torch.cuda.set_device(args.gpu)
#cudnn.benchmark = True
#torch.manual_seed(args.seed)
#cudnn.enabled=True
#torch.cuda.manual_seed(args.seed)
#logging.info('gpu device = %d' % args.gpu)
#logging.info("args = %s", args)

criterion = nn.CrossEntropyLoss()
criterion = criterion.cuda()
	

def batchify1(data, seq_len, bsz, args):
   nbatch = data.size(0) // (seq_len * bsz)
   data = data.narrow(0, 0, nbatch * bsz * seq_len)
   data = data.view(bsz * nbatch, seq_len).t().contiguous()
   print(data.size())
   #if args.cuda:
   data = data.cuda()
   return data

import data 
import torch.utils.data as data_utils

## hs,athaliana,celegans,dmelanogaster
data_species= args.data 

#model_species=args.model

## acc,don
typ=args.type
test_fil=str(args.test_file)
#pdb.set_trace()
#file_test_seq='/media/appadmin/MY_BOOK/data/splicing/splice2deep_data/proc_' + data_species +'/test_' + data_species + '_' + typ +'_seq.txt'
file_test_seq=test_fil
file_test_label=test_fil.split("seq",1)[0] +'label.txt'
#file_test_label='/media/appadmin/MY_BOOK/data/splicing/splice2deep_data/proc_' + data_species +'/test_' + data_species + '_' + typ +'_label.txt'
lab_dic = {
    "1": np.array([0, 1]),
    "0": np.array([1, 0])
}
#pdb.set_trace()
sub_length = 1
#H = np.array(range(602)).reshape(602,1)
test_Seq = [line.rstrip('\n')[:-1] for line in open(file_test_seq)]
test_Raw_lab = [line.rstrip('\n') for line in open(file_test_label)]
test_LABEL = seq2num(test_Raw_lab, lab_dic)
test_n = len(test_Raw_lab)
#pdb.set_trace()
test_a = test_Seq[1]
test_elements = element(test_a)
test_mapping_dic = combination(test_elements, sub_length)
if len(test_Seq[0])==140:
    H = np.array(range(142)).reshape(142,1)
else:
    H = np.array(range(602)).reshape(602,1)
test_d_1,test_d_2 = H.shape
test_DATA_ = -1. * np.ones((test_n, test_d_1, test_d_2, 4 ** sub_length))
for i in range(test_n):
        test_DATA_[i, :, :]= plot_hb_dna(seq=test_Seq[i],H_curve=H,sub_length=sub_length, map_dic=test_mapping_dic)
test_IMG = test_DATA_
test_IMG=np.transpose(test_IMG,[0, 2, 1, 3])
test_LABELS= test_LABEL
test_d1,test_d2,test_d3,test_d4 = test_IMG.shape
test_LABELS=torch.from_numpy(test_LABELS)
test_IMG=torch.from_numpy(test_IMG)
test_data = data_utils.TensorDataset(test_IMG,test_LABELS)
num_test_sep=len(test_data)
indices_test=list(range(num_test_sep))
split_test=int(np.floor(num_test_sep))
test_idx_sep=np.random.choice(indices_test, size=split_test, replace=False)
test_sampler_sep = SubsetRandomSampler(test_idx_sep)
test_queue = torch.utils.data.DataLoader(test_data,batch_size=args.val_size, sampler=test_sampler_sep)

print('*********************************************************************') 
print('*********************************************************************') 
print('*********************************************************************') 
print('Number of Unseen %s test samples: %d '%(data_species,test_n)) 
print('*********************************************************************') 
print('*********************************************************************') 
print('*********************************************************************') 


def testinfer(test_queue, model, criterion):
  auc = utils.AvgrageMeter()
  top1 = utils.AvgrageMeter()
  top5 = utils.AvgrageMeter()
  #model.eval()
  y_true, y_pred, auc_pred = [], [], []
  for step, (input, target) in enumerate(test_queue):
    input=input.float()
    #input = Variable(input).cuda()
    input=input.cuda()
    target=target.cuda()
    
    #target = Variable(target).cuda()
    #pdb.set_trace()
    logits,_= model(input)
    #loss = criterion(logits,torch.max(target, 1)[1])
    #pdb.set_trace()
    #aa=logits.cpu().data.numpy()
    #aucpred = np.divide(np.exp(aa),  np.sum(np.exp(aa), axis=1).reshape((aa.shape[0],1)))[:, 0]
    pred = torch.max(logits.data, dim=1)[1].cpu().numpy().tolist()
    #target=torch.max(target, 1)[1]
    #pdb.set_trace()
    #y_pred.extend(pred)
    #y_true.extend(target.data)
    bb=torch.max(target, 1)[1]
    cc= bb.cpu().data.numpy()
    fpr, tpr, thresholds = metrics.roc_curve(cc,pred)
    aucpred= metrics.auc(fpr, tpr)
    prec1, prec5 = utils.accuracy(logits, target, topk=(1, 5))
    n = input.size(0)
    #pdb.set_trace()
    auc.update(aucpred.item(), n)
    top1.update(prec1.item(), n)
    top5.update(prec5.item(), n)

    if step % args.report_freq == 0:
      logging.info('Test %03d %f %f', step, top1.avg, top5.avg)
    target=torch.max(target, 1)[1]
    #auc_pred.extend(aucpred)
    y_pred.extend(pred)
    #pdb.set_trace()
    y_true.extend(target.data)
    #pdb.set_trace()
  return top1.avg,y_pred,y_true,auc

modl='/media/appadmin/MY_BOOK/data/darts_revision/models_new/model_all_'+ typ +'_'+ str(len(test_Seq[0])+1) + '.pt' 

model = torch.load(modl)
parallel_model = model.cuda()

test_acc,y_pred,y_true,auc_pred = testinfer(test_queue, model, criterion)
logging.info('=' * 89)
logging.info('Prediction on TEST '+ data_species + ' ' + typ + 'data using ' + ' ' + typ + 'model'  )
logging.info(' test_acc %f', test_acc)
#logging.info(' test_loss %f', test_obj)
test_f1 = metrics.f1_score(torch.stack(y_true).tolist(), y_pred, average='macro')
logging.info(' F1 Score %f', test_f1)
#pdb.set_trace()
logging.info(' Precision, Recall and F1-Score...')
logging.info(metrics.classification_report(torch.stack(y_true).tolist(), y_pred))
#logging.info(metrics.classification_report(y_true, y_pred, target_names=['POS', 'NEG']))
logging.info(' Confusion Matrix...')
cm = metrics.confusion_matrix(torch.stack(y_true).tolist(), y_pred)
logging.info(cm)
logging.info(' roc_auc_score...')
#logging.info(metrics.roc_auc_score(y_true, auc_pred))
logging.info(auc_pred)
logging.info('=' * 89)

